{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIOBSsVQiItRhLauv292T5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GochiStuff/walmart-sales-predictor/blob/main/walmart_sales_predict_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uMIMLeb5VfUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7469b596-973b-494a-9fde-bae5d79edebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Dataset downloaded to: /root/.cache/kagglehub/datasets/mikhail1681/walmart-sales/versions/2\n",
            "\n",
            "CSV files found:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Listing CSV files: 100%|██████████| 1/1 [00:00<00:00, 7738.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.cache/kagglehub/datasets/mikhail1681/walmart-sales/versions/2/Walmart_Sales.csv\n",
            "\n",
            "Loading data from: /root/.cache/kagglehub/datasets/mikhail1681/walmart-sales/versions/2/Walmart_Sales.csv\n",
            "Data loaded. Columns in dataset: ['Store', 'Date', 'Weekly_Sales', 'Holiday_Flag', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "Splitting data into training and testing sets...\n",
            "Data split complete: 5148 training samples and 1287 testing samples.\n",
            "\n",
            "Starting grid search over hyperparameters...\n",
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid search complete.\n",
            "\n",
            "Best Parameters Found: {'regressor__eta0': 0.0001, 'regressor__learning_rate': 'invscaling', 'regressor__penalty': 'l1'}\n",
            "\n",
            "Evaluating the best model on test data...\n",
            "\n",
            "Best Model Evaluation:\n",
            "Test Accuracy (R²): 0.525284952182116\n",
            "Mean Squared Error: 152931619554.85226\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import kagglehub\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Download Dataset ---\n",
        "print(\"Downloading dataset...\")\n",
        "path = kagglehub.dataset_download(\"mikhail1681/walmart-sales\")\n",
        "print(\"Dataset downloaded to:\", path)\n",
        "\n",
        "# --- Locate CSV Files ---\n",
        "files = list(Path(path).rglob(\"*.csv\"))\n",
        "print(\"\\nCSV files found:\")\n",
        "for file in tqdm(files, desc=\"Listing CSV files\"):\n",
        "    print(file)\n",
        "\n",
        "# --- Load Data ---\n",
        "data_file = files[0]\n",
        "print(\"\\nLoading data from:\", data_file)\n",
        "data = pd.read_csv(data_file)\n",
        "print(\"Data loaded. Columns in dataset:\", data.columns.tolist())\n",
        "\n",
        "# --- Data Preprocessing ---\n",
        "print(\"\\nPreprocessing data...\")\n",
        "\n",
        "# Process Date column: extract date features\n",
        "if 'Date' in data.columns:\n",
        "    data['Date'] = pd.to_datetime(data['Date'], dayfirst=True)\n",
        "    data['Year'] = data['Date'].dt.year\n",
        "    data['Month'] = data['Date'].dt.month\n",
        "    data['Day'] = data['Date'].dt.day\n",
        "    data['WeekOfYear'] = data['Date'].dt.isocalendar().week\n",
        "    data.drop('Date', axis=1, inplace=True)\n",
        "\n",
        "# Process IsHoliday column: convert boolean/string to integer\n",
        "if 'IsHoliday' in data.columns:\n",
        "    data['IsHoliday'] = data['IsHoliday'].astype(int)\n",
        "\n",
        "# Assume the target column is Weekly_Sales; check that it exists.\n",
        "target = 'Weekly_Sales'\n",
        "if target not in data.columns:\n",
        "    raise ValueError(\"Target column 'Weekly_Sales' not found in dataset.\")\n",
        "\n",
        "# Identify categorical features (if they exist)\n",
        "categorical_cols = []\n",
        "if 'Store' in data.columns:\n",
        "    categorical_cols.append('Store')\n",
        "if 'Dept' in data.columns:\n",
        "    categorical_cols.append('Dept')\n",
        "\n",
        "# Identify numeric features (we expect our date features and IsHoliday)\n",
        "numeric_cols = []\n",
        "for col in ['Year', 'Month', 'Day', 'WeekOfYear', 'IsHoliday']:\n",
        "    if col in data.columns:\n",
        "        numeric_cols.append(col)\n",
        "\n",
        "# Define features and target\n",
        "X = data.drop(target, axis=1)\n",
        "y = data[target]\n",
        "\n",
        "# --- Split Data ---\n",
        "print(\"\\nSplitting data into training and testing sets...\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(\"Data split complete: {} training samples and {} testing samples.\".format(len(X_train), len(X_test)))\n",
        "\n",
        "# --- Build Preprocessing Pipeline ---\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_cols),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# --- Build the Overall Pipeline ---\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', SGDRegressor(random_state=42, max_iter=1500, tol=None))\n",
        "])\n",
        "\n",
        "# --- Hyperparameter Tuning ---\n",
        "# We'll tune some hyperparameters of SGDRegressor.\n",
        "param_grid = {\n",
        "    'regressor__eta0': [0.0001, 0.001, 0.01],\n",
        "    'regressor__learning_rate': ['constant', 'optimal', 'invscaling'],\n",
        "    'regressor__penalty': ['l2', 'l1', 'elasticnet']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='r2', verbose=1, n_jobs=-1)\n",
        "print(\"\\nStarting grid search over hyperparameters...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Grid search complete.\")\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"\\nBest Parameters Found:\", grid_search.best_params_)\n",
        "\n",
        "# --- Evaluate the Best Model ---\n",
        "print(\"\\nEvaluating the best model on test data...\")\n",
        "y_pred = best_model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "print(\"\\nBest Model Evaluation:\")\n",
        "print(\"Test Accuracy (R²):\", r2)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ]
    }
  ]
}